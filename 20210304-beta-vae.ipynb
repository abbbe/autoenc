{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thursday 4/03/2021\n",
    "\n",
    "* Implemented sigma-VAE\n",
    "\n",
    "Next:\n",
    "\n",
    "* Scatterplot 3D\n",
    "* How does it fluctuate depending on network architecture, nlats, training protocol, etc\n",
    "* Explore fold area in L0/L1 space. For each frame show:\n",
    " * image of gym robot,\n",
    " * colored L0/L1 scatterplot, with a red cross showing current latent state,\n",
    " * image reconstructed by the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OoMQk_5c4UYm",
    "outputId": "02cc896f-38e0-4a92-81ce-c20a7322369d"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of dataset load helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_dataset(filename):\n",
    "    with open(filename, 'rb') as handle:\n",
    "        dataset = pickle.load(handle)\n",
    "        if isinstance(dataset, dict):\n",
    "            return dataset\n",
    "        return dataset[0] # dataset-random-100k.mdict.pickle case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = load_dataset('dataset-random-100k.mdict.pickle')\n",
    "#dataset = load_dataset('dataset-grid-10-1000.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of env image vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_ax(ax):\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "def _imshow(ax, img):\n",
    "    if img is not None:\n",
    "        ax.imshow(img, cmap='Greys', origin='lower')\n",
    "    _clean_ax(ax)\n",
    "        \n",
    "def plot_Y(img_array):\n",
    "    assert(img_array.shape[-1] == 1)\n",
    "    fig, axs = plt.subplots(figsize=(2, 2))\n",
    "    _imshow(axs, img_array[..., 0])\n",
    "    return fig, axs\n",
    "\n",
    "def plot_Ys(img_array, title=None, ncols=5):\n",
    "    assert(ncols > 0)\n",
    "\n",
    "    nimgs = img_array.shape[0]\n",
    "    if nimgs == 0:\n",
    "        return None, None\n",
    "    elif nimgs == 1:\n",
    "        return plot_Y(img_array[0,...])\n",
    "    elif nimgs <= ncols:\n",
    "        ncols = nimgs\n",
    "        fig, axs = plt.subplots(1, ncols, figsize=(2*ncols, 2))\n",
    "\n",
    "        for i in range(ncols):\n",
    "            _imshow(axs[i], img_array[i,...])\n",
    "    else:\n",
    "        nrows = int((nimgs-1)/ ncols) + 1\n",
    "        fig, axs = plt.subplots(nrows, ncols, figsize=(2*ncols, 2*nrows))\n",
    "\n",
    "        for i in range(nrows):\n",
    "            for j in range(ncols):\n",
    "                k = i*ncols + j\n",
    "                if k < nimgs:\n",
    "                    img = img_array[k,...]\n",
    "                else:\n",
    "                    img = None\n",
    "                _imshow(axs[i][j], img)\n",
    "                    \n",
    "    if title is not None:\n",
    "        fig.suptitle(\"%s (%s)\" % (title, str(img_array.shape)))\n",
    "        \n",
    "    return fig, axs\n",
    "\n",
    "def plot_Y_YY(img_array1, img_array2, title=None, fig=None, axs=None):\n",
    "    if fig is None and axs is None:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(4, 2))\n",
    "        \n",
    "    _imshow(axs[0], img_array1)\n",
    "    _imshow(axs[1], img_array2)\n",
    "\n",
    "    if title is not None:\n",
    "        fig.suptitle(title)\n",
    "        \n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _=plot_Ys(dataset['Y'][0:10,...], title=\"First 10 elements of dataset['Y']\", ncols=5)\n",
    "# _=plot_Y_YY(dataset_grid['Y'][0], dataset_grid_out['YY'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of data (in and lat) visualization helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_scatter(data1, x1, i1, data2, x2, i2):\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    ax.scatter(data1[x1][:,i1], data2[x2][:,i2], 1)\n",
    "    ax.set_xlabel(\"%s%d\" % (x1, i1))\n",
    "    ax.set_ylabel(\"%s%d\" % (x2, i2))\n",
    "    ax.grid()\n",
    "\n",
    "def fine_scatter_color(data1, x1, i1, data2, x2, i2, c=None, size=10, ax=None):\n",
    "    if ax is None:\n",
    "        _fig, ax = plt.subplots(figsize=(size, size))\n",
    "        \n",
    "    ax.set_facecolor('xkcd:black')\n",
    "\n",
    "    x, y = data1[x1][:,i1], data2[x2][:,i2]\n",
    "    ax.scatter(x, y, 1, c=c)\n",
    "    ax.set_xlabel(\"%s%d\" % (x1, i1))\n",
    "    ax.set_ylabel(\"%s%d\" % (x2, i2))\n",
    "    #ax.grid()\n",
    "\n",
    "def fine_scatter_sum(data1, x1, i1a, i1b, data2, x2, i2):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    x = data1[x1][:,i1a] + data1[x1][:,i1b]\n",
    "    ax.scatter(x, data2[x2][:,i2], 1)\n",
    "    \n",
    "    ax.set_xlabel(\"%s(%d+%d)\" % (x1, i1a, i1b))\n",
    "    ax.set_ylabel(\"%s%d\" % (x2, i2))\n",
    "    ax.grid()\n",
    "\n",
    "def fine_scatter_color_sum(data1, x1, i1a, i1b, data2, x2, i2, c=None, size=10, ax=None):\n",
    "    if ax is None:\n",
    "        _fig, ax = plt.subplots(figsize=(size, size))\n",
    "        \n",
    "    ax.set_facecolor('xkcd:black')\n",
    "\n",
    "    x = data1[x1][:,i1a] + data1[x1][:,i1b]\n",
    "    y = data2[x2][:,i2]\n",
    "    ax.scatter(x, data2[x2][:,i2], 1, c)\n",
    "    \n",
    "    ax.set_xlabel(\"%s(%d+%d)\" % (x1, i1a, i1b))\n",
    "    ax.set_ylabel(\"%s%d\" % (x2, i2))\n",
    "\n",
    "def fine_scatter_color_sub(data1, x1, i1a, i1b, data2, x2, i2, c=None, size=10, ax=None):\n",
    "    if ax is None:\n",
    "        _fig, ax = plt.subplots(figsize=(size, size))\n",
    "        \n",
    "    ax.set_facecolor('xkcd:black')\n",
    "\n",
    "    x = data1[x1][:,i1a] - data1[x1][:,i1b]\n",
    "    y = data2[x2][:,i2]\n",
    "    ax.scatter(x, data2[x2][:,i2], 1, c)\n",
    "    \n",
    "    ax.set_xlabel(\"%s(%d-%d)\" % (x1, i1a, i1b))\n",
    "    ax.set_ylabel(\"%s%d\" % (x2, i2))\n",
    "\n",
    "def display_xvars(data):\n",
    "    nLat = data['L'].shape[1]\n",
    "    nVoltages = data['A'].shape[1]\n",
    "\n",
    "    fig, axs = plt.subplots(nLat+1, nVoltages+1)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for i in range(nLat):\n",
    "      for j in range(nVoltages):\n",
    "        title = \"volt%d vs lat%d\" % (j, i)\n",
    "        axs[i][j].title.set_text(title)\n",
    "        axs[i][j].plot(data['L'][:, i], data['A'][:,j], '.')\n",
    "\n",
    "    axs[nLat][0].title.set_text(\"volt0 vs volt1\")\n",
    "    axs[nLat][0].plot(data['A'][:,1], data['A'][:,0], '.')\n",
    "\n",
    "    axs[0][nVoltages].title.set_text(\"lat1 vs lat0\")\n",
    "    axs[0][nVoltages].plot(data['L'][:,0], data['L'][:,1], '.')\n",
    "\n",
    "    _clean_ax(axs[1][2])\n",
    "    _clean_ax(axs[2][1])\n",
    "    _clean_ax(axs[2][2])\n",
    "\n",
    "def cycle_autoencoder0(ae, data, prefix=\"\", N=10):\n",
    "    out_data = dict()\n",
    "    \n",
    "    Y = data['Y']\n",
    "    \n",
    "    print(\"Y.shape=\" + str(Y.shape))\n",
    "    YY = ae['ae'].predict(Y)\n",
    "    YY = np.array(YY)\n",
    "    print(\"YY.shape=\" + str(YY.shape))\n",
    "    \n",
    "    out_data['YY'] = YY\n",
    "\n",
    "    # - Y\n",
    "    plot_Ys(Y[0:N,...], title=\"First %d elements of %sY\" % (N, prefix))\n",
    "   \n",
    "    # - YY\n",
    "    plot_Ys(YY[0:N,...], title=\"First %d elements of %sYY\" % (N, prefix))\n",
    "    \n",
    "    return out_data\n",
    "\n",
    "def cycle_autoencoder(ae, data, prefix=\"\", N=10, vae=False, display=False):\n",
    "    Y = data['Y']\n",
    "    \n",
    "    if display:\n",
    "        print(\"Y.shape=\" + str(Y.shape))\n",
    "    L = ae['enc'].predict(Y)\n",
    "    L = np.array(L)\n",
    "    if display:\n",
    "        print(\"L.shape=\" + str(L.shape))\n",
    "\n",
    "    if vae:\n",
    "        L = np.array(L)[2] # [z_mean, z_log_var, z] - take Z\n",
    "\n",
    "    YY = ae['dec'].predict(L)\n",
    "    YY = np.array(YY)\n",
    "    if display:\n",
    "        print(\"YY.shape=\" + str(YY.shape))\n",
    "    \n",
    "    data['L'] = L # FIXME\n",
    "    data['YY'] = YY # FIXME\n",
    "\n",
    "    out_data = dict()\n",
    "    out_data['L'] = L\n",
    "    out_data['YY'] = YY\n",
    "\n",
    "    # - Y\n",
    "    if display:\n",
    "        plot_Ys(Y[0:N,...], title=\"First %d elements of %sY\" % (N, prefix))\n",
    "\n",
    "        # - L\n",
    "        fig, axs = plt.subplots(1, L.shape[1])\n",
    "        fig.suptitle(\"Latent variables %s\" % (str(L.shape)))\n",
    "        for i in range(L.shape[1]):\n",
    "            axs[i].hist(L[:,i])    \n",
    "\n",
    "        # - YY\n",
    "        plot_Ys(YY[0:N,...], title=\"First %d elements of %sYY\" % (N, prefix))\n",
    "\n",
    "        display_xvars(data)\n",
    "    \n",
    "    return out_data    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementations of model save and load methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(model, prefix):\n",
    "    model['ae'].save(prefix + '-ae.h5')\n",
    "    model['enc'].save(prefix + '-enc.h5')\n",
    "    model['dec'].save(prefix + '-dec.h5')\n",
    "    print(\"Models saved to \" + prefix + \" ...\")\n",
    "\n",
    "def load_models(prefix):\n",
    "    model = dict()\n",
    "    for k in ['ae', 'enc', 'dec']:\n",
    "        fname = prefix + '-' + k + '.h5'\n",
    "        model[k] = keras.models.load_model(fname)\n",
    "    return model\n",
    "\n",
    "# VAE models cannot be saved by the above methods, can only save weights\n",
    "\n",
    "def save_models_weights(model, prefix):\n",
    "    model['ae'].save_weights(prefix + '-ae.h5w')\n",
    "    model['enc'].save_weights(prefix + '-enc.h5w')\n",
    "    model['dec'].save_weights(prefix + '-dec.h5w')\n",
    "    print(\"Models weights saved to \" + prefix + \" ...\")\n",
    "    \n",
    "def load_models_weights(model, prefix):\n",
    "    model['ae'].load_weights(prefix + '-ae.h5w')\n",
    "    model['enc'].load_weights(prefix + '-enc.h5w')\n",
    "    model['dec'].load_weights(prefix + '-dec.h5w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize L0/L1 space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_lat_space(dataset_grid, dataset_grid_out, sheet):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(15,12))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if sheet == 1:\n",
    "        fine_scatter_color(dataset_grid, 'A', 0, dataset_grid_out, 'L' , 0, dataset_grid['A'][:,1], ax=axs[0,0])\n",
    "        fine_scatter_color(dataset_grid, 'A', 1, dataset_grid_out, 'L' , 1, dataset_grid['A'][:,0], ax=axs[0,1])\n",
    "\n",
    "        fine_scatter_color(dataset_grid, 'A', 0, dataset_grid_out, 'L' , 1, dataset_grid['A'][:,1], ax=axs[1,0])\n",
    "        fine_scatter_color(dataset_grid, 'A', 1, dataset_grid_out, 'L' , 0, dataset_grid['A'][:,0], ax=axs[1,1])\n",
    "\n",
    "    elif sheet == 2:\n",
    "        fine_scatter_color_sum(dataset_grid, 'A', 0, 1, dataset_grid_out, 'L', 0, dataset_grid_out['L'][:,1], ax=axs[0,0])\n",
    "        fine_scatter_color_sum(dataset_grid, 'A', 0, 1, dataset_grid_out, 'L', 1, dataset_grid_out['L'][:,0], ax=axs[0,1])\n",
    "\n",
    "        fine_scatter_color_sub(dataset_grid, 'A', 0, 1, dataset_grid_out, 'L', 0, dataset_grid_out['L'][:,1], ax=axs[1,0])\n",
    "        fine_scatter_color_sub(dataset_grid, 'A', 0, 1, dataset_grid_out, 'L', 1, dataset_grid_out['L'][:,0], ax=axs[1,1])\n",
    "    else:\n",
    "        raise\n",
    "    \n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.beta_vae import build_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build_params = {'epochs': 2, 'convs': [16, 8, 8]}\n",
    "#autoencoder = build_autoencoder((64, 64, 1), 2, build_params)\n",
    "\n",
    "#load_models_weights(autoencoder, \"trained-models/20210302-vae\") # NB: build the model first\n",
    "# or\n",
    "#train_model(autoencoder, dataset, val_dataset, build_params, \"test1037\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.beta_vae import build_autoencoder\n",
    "\n",
    "DATASETDIR = \"datasets.balls\"\n",
    "\n",
    "dataset = load_dataset(DATASETDIR + \"/dataset-random-100k.pickle\")\n",
    "dataset_grid = load_dataset(DATASETDIR + \"/dataset-grid-10-1000.pickle\")\n",
    "\n",
    "dataset_val = load_dataset(DATASETDIR + \"/dataset-random-10k.pickle\")\n",
    "dataset_val = {'A': dataset_val['A'][:500], 'Y': dataset_val['Y'][:500]} # take a piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "def animate_Y_YYs(ys, yys, outfile):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(4, 2))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    _clean_ax(axs[0])\n",
    "    _clean_ax(axs[1])\n",
    "\n",
    "    def animate(frame):\n",
    "        _imshow(axs[0], ys[frame])\n",
    "        _imshow(axs[1], yys[frame])\n",
    "        return (fig,)\n",
    "\n",
    "    N = ys.shape[0]\n",
    "    assert(N == yys.shape[0])\n",
    "    ani = animation.FuncAnimation(fig, animate, frames=range(N), blit=True)\n",
    "    ani.save(outfile)\n",
    "    fig.clf()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "\n",
    "BASE_DIR = \"20210304-beta-vae.balls/rand_100k-grid_10_1000\"\n",
    "TENSORBOARD_LOGS_DIR =  \"%s/tensorboard-logs\" % BASE_DIR\n",
    "TRAINED_MODELS_DIR = \"%s/trained-models\" % BASE_DIR\n",
    "IMGS_DIR = \"%s/imgs\" % BASE_DIR\n",
    "\n",
    "for dir in [BASE_DIR, TENSORBOARD_LOGS_DIR, TRAINED_MODELS_DIR, IMGS_DIR]:\n",
    "    if not os.path.isdir(dir):\n",
    "        os.mkdir(dir)\n",
    "\n",
    "def train_model(model, dataset, val_dataset, build_params, suffix):\n",
    "    ae = model['ae']\n",
    "    \n",
    "    logdir = os.path.join((\"%s/%s\" % (TENSORBOARD_LOGS_DIR, suffix)), datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir) #, histogram_freq=1)\n",
    "    \n",
    "    # FIXME ae.fit(dataset['Y'], validation_data=(val_dataset['Y'], val_dataset['Y']), callbacks=[tensorboard_callback],\n",
    "    ae.fit(dataset['Y'], callbacks=[tensorboard_callback],\n",
    "        epochs=build_params['epochs'], batch_size=128, verbose=0)\n",
    "    \n",
    "    save_models_weights(model, \"%s/%s\" % (TRAINED_MODELS_DIR, suffix))\n",
    "    \n",
    "def cycle(dataset, dataset_grid, dataset_val, build_params, suffix):\n",
    "    print(\"*** run(%s, %s)\" % (str(build_params), suffix))\n",
    "    \n",
    "    vis_fname = \"%s/%sa.png\" % (IMGS_DIR, suffix)\n",
    "    vis_fname2 = \"%s/%sb.png\" % (IMGS_DIR, suffix)\n",
    "    ani_fname = \"%s/%s.mp4\" % (IMGS_DIR, suffix)\n",
    "    \n",
    "    if os.path.isfile(vis_fname):\n",
    "        print(\"%s exists, skipping ...\" % vis_fname)\n",
    "        return\n",
    "    \n",
    "    print(\"building and training vae, build_params=%s\" % str(build_params))\n",
    "    keras.backend.clear_session()\n",
    "    autoencoder = build_autoencoder((64, 64, 1), 2, build_params)\n",
    "    train_model(autoencoder, dataset, dataset_val, build_params, suffix)\n",
    "\n",
    "    print(\"running vae on grid dataset, saving visualization into %s\" % (vis_fname))    \n",
    "    dataset_grid_out = cycle_autoencoder(autoencoder, dataset_grid, vae=True, display=False)\n",
    "    \n",
    "    fig, axs = visualize_lat_space(dataset_grid, dataset_grid_out, sheet=1)\n",
    "    fig.savefig(vis_fname)\n",
    "    fig.clf()\n",
    "    \n",
    "    fig, axs = visualize_lat_space(dataset_grid, dataset_grid_out, sheet=2)\n",
    "    fig.savefig(vis_fname2)\n",
    "    fig.clf()\n",
    "\n",
    "    NANIFRAMES = 20\n",
    "    print(\"saving ani visualization (for %d datapoints from grid dataset) into %s\" % (NANIFRAMES, ani_fname))\n",
    "    rng = np.random.default_rng()\n",
    "    ani_i = rng.choice(range(dataset_grid['Y'].shape[0]), size=NANIFRAMES) # choose 20 random items from the dataset_grid\n",
    "    animate_Y_YYs(dataset_grid['Y'][ani_i], dataset_grid_out['YY'][ani_i], outfile=ani_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build_params = {'epochs': 2, 'convs': [16, 8, 8]}\n",
    "#autoencoder = build_autoencoder((64, 64, 1), 2, build_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_models_weights(autoencoder, \"trained-models/20210302-vae\") # NB: build the model first\n",
    "#train_model(autoencoder, dataset, dataset_val, build_params, \"test1037\")\n",
    "#dataset_val_out = cycle_autoencoder(autoencoder, dataset_val, vae=True)\n",
    "#animate_Y_YYs(dataset_val['Y'][:20], dataset_val_out['YY'][:20], outfile='test-animate_Y_YYs.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cycle(dataset, dataset_grid, None, {'epochs': 1, 'convs': [16, 8, 8]}, \"test-cycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** run({'epochs': 1, 'convs': [16, 8, 8]}, convs_16_8_8-epochs_1-0)\n",
      "building and training vae, build_params={'epochs': 1, 'convs': [16, 8, 8]}\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[128,16,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node encoder/conv2d/Conv2D (defined at C:\\Users\\alexa\\Documents\\dvp\\autoenc\\models\\beta_vae.py:44) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_14166]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node encoder/conv2d/Conv2D:\n IteratorGetNext (defined at <ipython-input-18-606369a7d560>:20)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-13bfba889f43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuffix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"convs_16_8_8-epochs_%d-%d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mcycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'convs'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-606369a7d560>\u001b[0m in \u001b[0;36mcycle\u001b[1;34m(dataset, dataset_grid, dataset_val, build_params, suffix)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mautoencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_autoencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"running vae on grid dataset, saving visualization into %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvis_fname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-606369a7d560>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, dataset, val_dataset, build_params, suffix)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# FIXME ae.fit(dataset['Y'], validation_data=(val_dataset['Y'], val_dataset['Y']), callbacks=[tensorboard_callback],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     ae.fit(dataset['Y'], callbacks=[tensorboard_callback],\n\u001b[1;32m---> 20\u001b[1;33m         epochs=build_params['epochs'], batch_size=128, verbose=0)\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0msave_models_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"%s/%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTRAINED_MODELS_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[128,16,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node encoder/conv2d/Conv2D (defined at C:\\Users\\alexa\\Documents\\dvp\\autoenc\\models\\beta_vae.py:44) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_14166]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node encoder/conv2d/Conv2D:\n IteratorGetNext (defined at <ipython-input-18-606369a7d560>:20)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "for epochs in [1, 10, 25]:\n",
    "    for i in range(5):\n",
    "        suffix = \"convs_16_8_8-epochs_%d-%d\" % (epochs, i)\n",
    "        cycle(dataset, dataset_grid, None, {'epochs': epochs, 'convs': [16, 8, 8]}, suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for epochs in [100]:\n",
    "#    for i in range(5):\n",
    "#        suffix = \"convs_16_8_8-epochs_%d-%d\" % (epochs, i)\n",
    "#        cycle(dataset, val_dataset, {'epochs': epochs, 'convs': [16, 8, 8]}, suffix)\n",
    "#        \n",
    "#for epochs in [5, 25, 50, 100]:\n",
    "#    for i in range(5):\n",
    "#        suffix = \"convs_16_8_4-epochs_%d-%d\" % (epochs, i)\n",
    "#        cycle(dataset, val_dataset, {'epochs': epochs, 'convs': [16, 8, 4]}, suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "robot-arm-vae2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
