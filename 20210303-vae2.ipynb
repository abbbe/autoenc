{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wednesday 3/03/2021\n",
    "\n",
    "* DONE: Use grid L0/L1 space for visualization\n",
    "* INPROGRESS: Train and run autoencoder for different number of epochs. Run several times with same settings. Assess impact.\n",
    "\n",
    "Next:\n",
    "\n",
    "* Explore impact of changing filters chain down to (2,2,2)\n",
    "* Scatterplot 3D\n",
    "* How does it fluctuate depending on network architecture, nlats, training protocol, etc\n",
    "* Explore fold area in L0/L1 space. For each frame show:\n",
    " * image of gym robot,\n",
    " * colored L0/L1 scatterplot, with a red cross showing current latent state,\n",
    " * image reconstructed by the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OoMQk_5c4UYm",
    "outputId": "02cc896f-38e0-4a92-81ce-c20a7322369d"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of dataset load helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_dataset(filename):\n",
    "    with open(filename, 'rb') as handle:\n",
    "        dataset = pickle.load(handle)\n",
    "        if isinstance(dataset, dict):\n",
    "            return dataset\n",
    "        return dataset[0] # dataset-random-100k.mdict.pickle case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = load_dataset('dataset-random-100k.mdict.pickle')\n",
    "#dataset = load_dataset('dataset-grid-10-1000.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of env image vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_ax(ax):\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "def _imshow(ax, img):\n",
    "    if img is not None:\n",
    "        ax.imshow(img, cmap='Greys', origin='lower')\n",
    "    _clean_ax(ax)\n",
    "        \n",
    "def plot_Y(img_array):\n",
    "    assert(img_array.shape[-1] == 1)\n",
    "    fig, axs = plt.subplots(figsize=(2, 2))\n",
    "    _imshow(axs, img_array[..., 0])\n",
    "    return fig, axs\n",
    "\n",
    "def plot_Ys(img_array, title=None, ncols=5):\n",
    "    assert(ncols > 0)\n",
    "\n",
    "    nimgs = img_array.shape[0]\n",
    "    if nimgs == 0:\n",
    "        return None, None\n",
    "    elif nimgs == 1:\n",
    "        return plot_Y(img_array[0,...])\n",
    "    elif nimgs <= ncols:\n",
    "        ncols = nimgs\n",
    "        fig, axs = plt.subplots(1, ncols, figsize=(2*ncols, 2))\n",
    "\n",
    "        for i in range(ncols):\n",
    "            _imshow(axs[i], img_array[i,...])\n",
    "    else:\n",
    "        nrows = int((nimgs-1)/ ncols) + 1\n",
    "        fig, axs = plt.subplots(nrows, ncols, figsize=(2*ncols, 2*nrows))\n",
    "\n",
    "        for i in range(nrows):\n",
    "            for j in range(ncols):\n",
    "                k = i*ncols + j\n",
    "                if k < nimgs:\n",
    "                    img = img_array[k,...]\n",
    "                else:\n",
    "                    img = None\n",
    "                _imshow(axs[i][j], img)\n",
    "                    \n",
    "    if title is not None:\n",
    "        fig.suptitle(\"%s (%s)\" % (title, str(img_array.shape)))\n",
    "        \n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _=plot_Ys(dataset['Y'][0:10,...], title=\"First 10 elements of dataset['Y']\", ncols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of data (in and lat) visualization helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_scatter(data1, x1, i1, data2, x2, i2):\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    ax.scatter(data1[x1][:,i1], data2[x2][:,i2], 1)\n",
    "    ax.set_xlabel(\"%s%d\" % (x1, i1))\n",
    "    ax.set_ylabel(\"%s%d\" % (x2, i2))\n",
    "    ax.grid()\n",
    "\n",
    "def fine_scatter_color(data1, x1, i1, data2, x2, i2, c=None, size=10, ax=None):\n",
    "    if ax is None:\n",
    "        _fig, ax = plt.subplots(figsize=(size, size))\n",
    "        \n",
    "    ax.set_facecolor('xkcd:black')\n",
    "\n",
    "    x, y = data1[x1][:,i1], data2[x2][:,i2]\n",
    "    ax.scatter(x, y, 1, c=c)\n",
    "    ax.set_xlabel(\"%s%d\" % (x1, i1))\n",
    "    ax.set_ylabel(\"%s%d\" % (x2, i2))\n",
    "    #ax.grid()\n",
    "\n",
    "def fine_scatter_sum(data1, x1, i1a, i1b, data2, x2, i2):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    x = data1[x1][:,i1a] + data1[x1][:,i1b]\n",
    "    ax.scatter(x, data2[x2][:,i2], 1)\n",
    "    \n",
    "    ax.set_xlabel(\"%s(%d+%d)\" % (x1, i1a, i1b))\n",
    "    ax.set_ylabel(\"%s%d\" % (x2, i2))\n",
    "    ax.grid()\n",
    "\n",
    "def fine_scatter_color_sum(data1, x1, i1a, i1b, data2, x2, i2, c=None, size=10, ax=None):\n",
    "    if ax is None:\n",
    "        _fig, ax = plt.subplots(figsize=(size, size))\n",
    "        \n",
    "    ax.set_facecolor('xkcd:black')\n",
    "\n",
    "    x = data1[x1][:,i1a] + data1[x1][:,i1b]\n",
    "    y = data2[x2][:,i2]\n",
    "    ax.scatter(x, data2[x2][:,i2], 1, c)\n",
    "    \n",
    "    ax.set_xlabel(\"%s(%d+%d)\" % (x1, i1a, i1b))\n",
    "    ax.set_ylabel(\"%s%d\" % (x2, i2))\n",
    "\n",
    "def fine_scatter_color_sub(data1, x1, i1a, i1b, data2, x2, i2, c=None, size=10, ax=None):\n",
    "    if ax is None:\n",
    "        _fig, ax = plt.subplots(figsize=(size, size))\n",
    "        \n",
    "    ax.set_facecolor('xkcd:black')\n",
    "\n",
    "    x = data1[x1][:,i1a] - data1[x1][:,i1b]\n",
    "    y = data2[x2][:,i2]\n",
    "    ax.scatter(x, data2[x2][:,i2], 1, c)\n",
    "    \n",
    "    ax.set_xlabel(\"%s(%d-%d)\" % (x1, i1a, i1b))\n",
    "    ax.set_ylabel(\"%s%d\" % (x2, i2))\n",
    "\n",
    "def display_xvars(data):\n",
    "    nLat = data['L'].shape[1]\n",
    "    nVoltages = data['A'].shape[1]\n",
    "\n",
    "    fig, axs = plt.subplots(nLat+1, nVoltages+1)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for i in range(nLat):\n",
    "      for j in range(nVoltages):\n",
    "        title = \"volt%d vs lat%d\" % (j, i)\n",
    "        axs[i][j].title.set_text(title)\n",
    "        axs[i][j].plot(data['L'][:, i], data['A'][:,j], '.')\n",
    "\n",
    "    axs[nLat][0].title.set_text(\"volt0 vs volt1\")\n",
    "    axs[nLat][0].plot(data['A'][:,1], data['A'][:,0], '.')\n",
    "\n",
    "    axs[0][nVoltages].title.set_text(\"lat1 vs lat0\")\n",
    "    axs[0][nVoltages].plot(data['L'][:,0], data['L'][:,1], '.')\n",
    "\n",
    "    _clean_ax(axs[1][2])\n",
    "    _clean_ax(axs[2][1])\n",
    "    _clean_ax(axs[2][2])\n",
    "\n",
    "def cycle_autoencoder0(ae, data, prefix=\"\", N=10):\n",
    "    out_data = dict()\n",
    "    \n",
    "    Y = data['Y']\n",
    "    \n",
    "    print(\"Y.shape=\" + str(Y.shape))\n",
    "    YY = ae['ae'].predict(Y)\n",
    "    YY = np.array(YY)\n",
    "    print(\"YY.shape=\" + str(YY.shape))\n",
    "    \n",
    "    out_data['YY'] = YY\n",
    "\n",
    "    # - Y\n",
    "    plot_Ys(Y[0:N,...], title=\"First %d elements of %sY\" % (N, prefix))\n",
    "   \n",
    "    # - YY\n",
    "    plot_Ys(YY[0:N,...], title=\"First %d elements of %sYY\" % (N, prefix))\n",
    "    \n",
    "    return out_data\n",
    "\n",
    "def cycle_autoencoder(ae, data, prefix=\"\", N=10, vae=False, display=False):\n",
    "    Y = data['Y']\n",
    "    \n",
    "    if display:\n",
    "        print(\"Y.shape=\" + str(Y.shape))\n",
    "    L = ae['enc'].predict(Y)\n",
    "    L = np.array(L)\n",
    "    if display:\n",
    "        print(\"L.shape=\" + str(L.shape))\n",
    "\n",
    "    if vae:\n",
    "        L = np.array(L)[2] # [z_mean, z_log_var, z] - take Z\n",
    "\n",
    "    YY = ae['dec'].predict(L)\n",
    "    YY = np.array(YY)\n",
    "    if display:\n",
    "        print(\"YY.shape=\" + str(YY.shape))\n",
    "    \n",
    "    data['L'] = L # FIXME\n",
    "    data['YY'] = YY # FIXME\n",
    "\n",
    "    out_data = dict()\n",
    "    out_data['L'] = L\n",
    "    out_data['YY'] = YY\n",
    "\n",
    "    # - Y\n",
    "    if display:\n",
    "        plot_Ys(Y[0:N,...], title=\"First %d elements of %sY\" % (N, prefix))\n",
    "\n",
    "        # - L\n",
    "        fig, axs = plt.subplots(1, L.shape[1])\n",
    "        fig.suptitle(\"Latent variables %s\" % (str(L.shape)))\n",
    "        for i in range(L.shape[1]):\n",
    "            axs[i].hist(L[:,i])    \n",
    "\n",
    "        # - YY\n",
    "        plot_Ys(YY[0:N,...], title=\"First %d elements of %sYY\" % (N, prefix))\n",
    "\n",
    "        display_xvars(data)\n",
    "    \n",
    "    return out_data    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementations of model save and load methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(model, prefix):\n",
    "    model['ae'].save(prefix + '-ae.h5')\n",
    "    model['enc'].save(prefix + '-enc.h5')\n",
    "    model['dec'].save(prefix + '-dec.h5')\n",
    "    print(\"Models saved to \" + prefix + \" ...\")\n",
    "\n",
    "def load_models(prefix):\n",
    "    model = dict()\n",
    "    for k in ['ae', 'enc', 'dec']:\n",
    "        fname = prefix + '-' + k + '.h5'\n",
    "        model[k] = keras.models.load_model(fname)\n",
    "    return model\n",
    "\n",
    "# VAE models cannot be saved by the above methods, can only save weights\n",
    "\n",
    "def save_models_weights(model, prefix):\n",
    "    model['ae'].save_weights(prefix + '-ae.h5w')\n",
    "    model['enc'].save_weights(prefix + '-enc.h5w')\n",
    "    model['dec'].save_weights(prefix + '-dec.h5w')\n",
    "    print(\"Models weights saved to \" + prefix + \" ...\")\n",
    "    \n",
    "def load_models_weights(model, prefix):\n",
    "    model['ae'].load_weights(prefix + '-ae.h5w')\n",
    "    model['enc'].load_weights(prefix + '-enc.h5w')\n",
    "    model['dec'].load_weights(prefix + '-dec.h5w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize L0/L1 space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_lat_space(dataset_grid, dataset_grid_out, sheet):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(15,12))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if sheet == 1:\n",
    "        fine_scatter_color(dataset_grid, 'A', 0, dataset_grid_out, 'L' , 0, dataset_grid['A'][:,1], ax=axs[0,0])\n",
    "        fine_scatter_color(dataset_grid, 'A', 1, dataset_grid_out, 'L' , 1, dataset_grid['A'][:,0], ax=axs[0,1])\n",
    "\n",
    "        fine_scatter_color(dataset_grid, 'A', 0, dataset_grid_out, 'L' , 1, dataset_grid['A'][:,1], ax=axs[1,0])\n",
    "        fine_scatter_color(dataset_grid, 'A', 1, dataset_grid_out, 'L' , 0, dataset_grid['A'][:,0], ax=axs[1,1])\n",
    "\n",
    "    elif sheet == 2:\n",
    "        fine_scatter_color_sum(dataset_grid, 'A', 0, 1, dataset_grid_out, 'L', 0, dataset_grid_out['L'][:,1], ax=axs[0,0])\n",
    "        fine_scatter_color_sum(dataset_grid, 'A', 0, 1, dataset_grid_out, 'L', 1, dataset_grid_out['L'][:,0], ax=axs[0,1])\n",
    "\n",
    "        fine_scatter_color_sub(dataset_grid, 'A', 0, 1, dataset_grid_out, 'L', 0, dataset_grid_out['L'][:,1], ax=axs[1,0])\n",
    "        fine_scatter_color_sub(dataset_grid, 'A', 0, 1, dataset_grid_out, 'L', 1, dataset_grid_out['L'][:,0], ax=axs[1,1])\n",
    "    else:\n",
    "        raise\n",
    "    \n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vae import build_autoencoder\n",
    "#autoencoder = build_autoencoder((64, 64, 1), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_models_weights(autoencoder, \"20210302-vae\") # NB: build the model first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vae import build_autoencoder\n",
    "\n",
    "dataset = load_dataset('datasets/dataset-random-100k.mdict.pickle')\n",
    "dataset_grid = load_dataset('datasets/dataset-grid-10-1000.pickle')\n",
    "\n",
    "val_dataset = load_dataset('datasets/dataset-random-10k.mdict.pickle')\n",
    "val_dataset = {'A': val_dataset['A'][:500], 'Y': val_dataset['Y'][:500]} # take a piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "\n",
    "BASE_DIR = \"20210303-vae2/rand_100k-grid_10_1000\"\n",
    "TENSORBOARD_LOGS_DIR =  \"%s/tensorboard-logs\" % BASE_DIR\n",
    "TRAINED_MODELS_DIR = \"%s/trained-models\" % BASE_DIR\n",
    "IMGS_DIR = \"%s/imgs\" % BASE_DIR\n",
    "\n",
    "for dir in [BASE_DIR, TENSORBOARD_LOGS_DIR, TRAINED_MODELS_DIR, IMGS_DIR]:\n",
    "    if not os.path.isdir(dir):\n",
    "        os.mkdir(dir)\n",
    "\n",
    "def train_model(model, dataset, val_dataset, build_params, suffix):\n",
    "    ae = model['ae']\n",
    "    \n",
    "    logdir = os.path.join((\"%s/%s\" % (TENSORBOARD_LOGS_DIR, suffix)), datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir) #, histogram_freq=1)\n",
    "    \n",
    "    # FIXME ae.fit(dataset['Y'], validation_data=(val_dataset['Y'], val_dataset['Y']), callbacks=[tensorboard_callback],\n",
    "    ae.fit(dataset['Y'], callbacks=[tensorboard_callback],\n",
    "        epochs=build_params['epochs'], batch_size=128, verbose=0)\n",
    "    \n",
    "    save_models_weights(model, \"%s/%s\" % (TRAINED_MODELS_DIR, suffix))\n",
    "    \n",
    "def run(dataset, val_dataset, build_params, suffix):\n",
    "    print(\"*** run(%s, %s)\" % (str(build_params), suffix))\n",
    "    \n",
    "    vis_fname = \"%s/%s.png\" % (IMGS_DIR, suffix)\n",
    "    vis_fname2 = \"%s/%s-2.png\" % (IMGS_DIR, suffix)\n",
    "    \n",
    "    if os.path.isfile(vis_fname):\n",
    "        print(\"%s exists, skipping ...\" % vis_fname)\n",
    "        return\n",
    "    \n",
    "    print(\"building and training vae, build_params=%s\" % str(build_params))\n",
    "    keras.backend.clear_session()\n",
    "    autoencoder = build_autoencoder((64, 64, 1), 2, build_params)\n",
    "    train_model(autoencoder, dataset, val_dataset, build_params, suffix)\n",
    "\n",
    "    print(\"running vae, saving visualization into %s\" % (vis_fname))\n",
    "    dataset_grid_out = cycle_autoencoder(autoencoder, dataset_grid, vae=True, display=False)\n",
    "    \n",
    "    fig, axs = visualize_lat_space(dataset_grid, dataset_grid_out, sheet=1)\n",
    "    fig.savefig(vis_fname)\n",
    "    fig.clf()\n",
    "    \n",
    "    fig, axs = visualize_lat_space(dataset_grid, dataset_grid_out, sheet=2)\n",
    "    fig.savefig(vis_fname2)\n",
    "    fig.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run({'epochs': 5, 'convs': [16, 8, 4, 2]}, \"test-conv_16_8_4-epochs_%d-%d\" % (epochs, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epochs in [1, 5, 10, 25, 50]:\n",
    "    for i in range(5):\n",
    "        suffix = \"convs_16_8_8-epochs_%d-%d\" % (epochs, i)\n",
    "        run(dataset, val_dataset, {'epochs': epochs, 'convs': [16, 8, 8]}, suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epochs in [100]:\n",
    "    for i in range(5):\n",
    "        suffix = \"convs_16_8_8-epochs_%d-%d\" % (epochs, i)\n",
    "        run(dataset, val_dataset, {'epochs': epochs, 'convs': [16, 8, 8]}, suffix)\n",
    "        \n",
    "for epochs in [5, 25, 50, 100]:\n",
    "    for i in range(5):\n",
    "        suffix = \"convs_16_8_4-epochs_%d-%d\" % (epochs, i)\n",
    "        run(dataset, val_dataset, {'epochs': epochs, 'convs': [16, 8, 4]}, suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "robot-arm-vae2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
